# File: run-all-once.yml
# Author: Ryoichi Ando (ryoichi.ando@zozo.com)
# License: Apache v2.0
# Generated by: run-all-once-gen.py

name: All Examples

on:
  workflow_dispatch:
    inputs:
      instance_type:
        description: 'EC2 instance type'
        required: true
        default: 'g6e.2xlarge'
        type: choice
        options:
          - g6.2xlarge
          - g6e.2xlarge
      region:
        description: 'AWS Region'
        required: true
        default: 'us-east-1'
        type: choice
        options:
          - us-east-1
          - us-east-2

jobs:
  run-batch-1:
    name: Run Batch 1
    runs-on: ubuntu-latest
    permissions:
      id-token: write
      contents: read

    env:
      AWS_REGION: ${{ github.event.inputs.region }}
      INSTANCE_TYPE: ${{ github.event.inputs.instance_type }}
      BRANCH: ${{ github.ref_name }}
      EXAMPLES: "belt cards codim curtain"
      WORKDIR: /home/ubuntu
      USER: ubuntu

    steps:
      - name: Show input parameters
        run: |
          echo "## Input Parameters - Batch 1"
          echo "Branch: ${{ github.ref_name }}"
          echo "Instance Type: ${{ github.event.inputs.instance_type }}"
          echo "Region: ${{ github.event.inputs.region }}"
          echo "Examples: belt cards codim curtain"

      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Configure AWS credentials via OIDC
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_ROLE_ARN }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Verify AWS authentication
        run: |
          echo "Testing AWS authentication..."
          aws sts get-caller-identity
          echo "AWS Region: $AWS_REGION"
          echo "Instance Type: $INSTANCE_TYPE"
          echo "Branch: $BRANCH"
          echo "Examples: $EXAMPLES"

      - name: Find Deep Learning AMI
        id: ami
        run: |
          echo "Finding latest Deep Learning AMI with GPU support..."
          AMI_ID=$(aws ec2 describe-images \
            --owners amazon \
            --filters \
              "Name=name,Values=Deep Learning Base OSS Nvidia Driver GPU AMI (Ubuntu 24.04)*" \
              "Name=state,Values=available" \
              "Name=architecture,Values=x86_64" \
            --query 'sort_by(Images, &CreationDate)[-1].ImageId' \
            --region "$AWS_REGION" \
            --output text)

          if [ "$AMI_ID" = "None" ] || [ -z "$AMI_ID" ]; then
            echo "ERROR: Deep Learning AMI not found in region $AWS_REGION"
            echo "This workflow requires the Deep Learning AMI with pre-installed NVIDIA drivers"
            echo "Please check if the AMI is available in your selected region"
            exit 1
          fi

          echo "AMI_ID=$AMI_ID" >> $GITHUB_OUTPUT
          echo "Found AMI: $AMI_ID"

      - name: Generate unique identifiers
        id: ids
        run: |
          TIMESTAMP=$(date +%Y%m%d%H%M%S)
          echo "TIMESTAMP=$TIMESTAMP" >> $GITHUB_OUTPUT

      - name: Retrieve SSH key from Parameter Store
        id: keypair
        run: |
          echo "Retrieving SSH private key from AWS Systems Manager..."
          KEY_NAME="${{ secrets.AWS_KEY_PAIR_NAME }}"

          # Retrieve the SSH private key from Parameter Store
          aws ssm get-parameter \
            --name "/github-actions/ec2/ssh-key" \
            --with-decryption \
            --query 'Parameter.Value' \
            --region "$AWS_REGION" \
            --output text > /tmp/github-actions-ec2.pem

          chmod 600 /tmp/github-actions-ec2.pem
          echo "SSH key retrieved successfully"
          echo "KEY_PATH=/tmp/github-actions-ec2.pem" >> $GITHUB_OUTPUT

      - name: Create user data script
        run: |
          cat > /tmp/user-data.sh << EOF
          #!/bin/bash
          set -e

          exec > >(tee -a /var/log/user-data.log)
          exec 2>&1

          echo "Starting user data script at \$(date)"

          # Install Rust (needed for cargo build)
          curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh -s -- -y
          source "\$HOME/.cargo/env"

          # Verify nvidia-smi is available
          if command -v nvidia-smi &> /dev/null; then
              echo "NVIDIA drivers confirmed"
              nvidia-smi
          else
              echo "Warning: nvidia-smi not found"
          fi

          # Create workspace directory
          mkdir -p ${{ env.WORKDIR }}/workspace
          chown -R ${{ env.USER }}:${{ env.USER }} ${{ env.WORKDIR }}/workspace

          nvidia-smi | tee /tmp/nvidia-smi-output.txt
          touch /tmp/setup-complete
          echo "Setup completed at \$(date)"
          EOF

      - name: Launch EC2 instance
        id: instance
        run: |
          INSTANCE_ID=$(aws ec2 run-instances \
            --image-id "${{ steps.ami.outputs.AMI_ID }}" \
            --instance-type "$INSTANCE_TYPE" \
            --key-name "${{ secrets.AWS_KEY_PAIR_NAME }}" \
            --security-group-ids "${{ secrets.AWS_SECURITY_GROUP_ID }}" \
            --block-device-mappings "DeviceName=/dev/sda1,Ebs={VolumeSize=256,VolumeType=gp3,DeleteOnTermination=true}" \
            --user-data file:///tmp/user-data.sh \
            --tag-specifications \
              "ResourceType=instance,Tags=[\
                {Key=Name,Value=gpu-runner-batch-1-${{ steps.ids.outputs.TIMESTAMP }}},\
                {Key=ManagedBy,Value=GitHubActions},\
                {Key=Purpose,Value=GPURunner},\
                {Key=Workflow,Value=${{ github.workflow }}},\
                {Key=RunId,Value=${{ github.run_id }}},\
                {Key=Branch,Value=${{ env.BRANCH }}},\
                {Key=Batch,Value=1}\
              ]" \
              "ResourceType=volume,Tags=[\
                {Key=Name,Value=gpu-runner-batch-1-${{ steps.ids.outputs.TIMESTAMP }}-volume},\
                {Key=ManagedBy,Value=GitHubActions},\
                {Key=Purpose,Value=GPURunner},\
                {Key=Workflow,Value=${{ github.workflow }}},\
                {Key=Batch,Value=1}\
              ]" \
            --instance-initiated-shutdown-behavior terminate \
            --query 'Instances[0].InstanceId' \
            --region "$AWS_REGION" \
            --output text)

          echo "INSTANCE_ID=$INSTANCE_ID" >> $GITHUB_OUTPUT
          echo "Instance launched: $INSTANCE_ID"

      - name: Wait for instance to be running
        run: |
          echo "Waiting for instance to be running..."
          aws ec2 wait instance-running \
            --instance-ids "${{ steps.instance.outputs.INSTANCE_ID }}" \
            --region "$AWS_REGION"

          PUBLIC_IP=$(aws ec2 describe-instances \
            --instance-ids "${{ steps.instance.outputs.INSTANCE_ID }}" \
            --query 'Reservations[0].Instances[0].PublicIpAddress' \
            --region "$AWS_REGION" \
            --output text)

          echo "Instance is running at: $PUBLIC_IP"
          echo "PUBLIC_IP=$PUBLIC_IP" >> $GITHUB_ENV

      - name: Wait for SSH availability
        run: |
          echo "Waiting for SSH to be available..."
          MAX_ATTEMPTS=30
          ATTEMPT=0

          while [ $ATTEMPT -lt $MAX_ATTEMPTS ]; do
            if ssh -o ConnectTimeout=5 -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null \
              -i "${{ steps.keypair.outputs.KEY_PATH }}" ${{ env.USER }}@${{ env.PUBLIC_IP }} "echo 'SSH ready'" 2>/dev/null; then
              echo "SSH connection established"
              break
            else
              ATTEMPT=$((ATTEMPT + 1))
              if [ $ATTEMPT -eq $MAX_ATTEMPTS ]; then
                echo "Failed to establish SSH connection"
                exit 1
              fi
              sleep 10
            fi
          done

      - name: Wait for instance setup
        run: |
          echo "Waiting for instance setup to complete..."
          MAX_WAIT=300
          ELAPSED=0

          while [ $ELAPSED -lt $MAX_WAIT ]; do
            if ssh -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null \
              -i "${{ steps.keypair.outputs.KEY_PATH }}" ${{ env.USER }}@${{ env.PUBLIC_IP }} \
              "test -f /tmp/setup-complete" 2>/dev/null; then
              echo "Instance setup completed"
              break
            else
              sleep 10
              ELAPSED=$((ELAPSED + 10))
              if [ $ELAPSED -ge $MAX_WAIT ]; then
                echo "Setup timeout, continuing anyway..."
                break
              fi
            fi
          done

      - name: Create archive of repository
        run: |
          echo "Creating repository archive..."
          git archive --format=tar.gz --output=/tmp/repo.tar.gz HEAD

      - name: Transfer repository to instance
        run: |
          echo "Transferring repository to instance..."
          scp -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null \
            -i "${{ steps.keypair.outputs.KEY_PATH }}" \
            /tmp/repo.tar.gz ${{ env.USER }}@${{ env.PUBLIC_IP }}:${{ env.WORKDIR }}/

          echo "Extracting repository on instance..."
          ssh -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null \
            -i "${{ steps.keypair.outputs.KEY_PATH }}" ${{ env.USER }}@${{ env.PUBLIC_IP }} \
            "cd ${{ env.WORKDIR }} && tar -xzf repo.tar.gz && rm repo.tar.gz"

      - name: Setup Python environment and run warmup
        run: |
          echo "Setting up Python environment and running warmup.py..."
          ssh -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null \
            -i "${{ steps.keypair.outputs.KEY_PATH }}" ${{ env.USER }}@${{ env.PUBLIC_IP }} << 'ENDSSH'
          set -e
          cd ${{ env.WORKDIR }}

          # Run warmup.py
          echo "Running warmup.py..."
          python3 warmup.py

          echo "Warmup completed"
          ENDSSH

      - name: Build Rust project
        run: |
          echo "Building Rust project with cargo..."
          ssh -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null \
            -i "${{ steps.keypair.outputs.KEY_PATH }}" ${{ env.USER }}@${{ env.PUBLIC_IP }} << 'ENDSSH'
          set -e
          cd ${{ env.WORKDIR }}

          # Setup Rust environment
          source "$HOME/.cargo/env"

          # Build the project
          echo "Running cargo build --release..."
          cargo build --release

          echo "Cargo build completed"
          ENDSSH

      - name: Setup CI directory
        run: |
          echo "Setting up CI directory..."
          ssh -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null \
            -i "${{ steps.keypair.outputs.KEY_PATH }}" ${{ env.USER }}@${{ env.PUBLIC_IP }} \
            "mkdir -p /tmp/ci"

      - name: Run belt
        run: |
          echo "Running belt..."
          ssh -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null \
            -i "${{ steps.keypair.outputs.KEY_PATH }}" ${{ env.USER }}@${{ env.PUBLIC_IP }} << 'ENDSSH'
          set -e
          cd ${{ env.WORKDIR }}

          # Activate Python environment
          source ~/.local/share/ppf-cts/venv/bin/activate

          # Convert notebook to Python script
          jupyter nbconvert --to python "examples/belt.ipynb" --output "/tmp/belt_base.py"

          # Create the runnable script with proper imports
          cat > /tmp/belt.py << 'PYEOF'
          import sys
          import os

          # Add the repository root to Python path so frontend can be imported
          sys.path.insert(0, '${{ env.WORKDIR }}')
          sys.path.insert(0, '${{ env.WORKDIR }}/frontend')

          # Set environment variables if needed
          os.environ['PYTHONPATH'] = '${{ env.WORKDIR }}:${{ env.WORKDIR }}/frontend:' + os.environ.get('PYTHONPATH', '')
          PYEOF

          # Append the converted notebook content
          cat "/tmp/belt_base.py" >> /tmp/belt.py

          # Run the example
          echo "belt" > frontend/.CI
          python3 /tmp/belt.py 2>&1 | tee /tmp/ci/belt.log
          ENDSSH

      - name: Run cards
        run: |
          echo "Running cards..."
          ssh -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null \
            -i "${{ steps.keypair.outputs.KEY_PATH }}" ${{ env.USER }}@${{ env.PUBLIC_IP }} << 'ENDSSH'
          set -e
          cd ${{ env.WORKDIR }}

          # Activate Python environment
          source ~/.local/share/ppf-cts/venv/bin/activate

          # Convert notebook to Python script
          jupyter nbconvert --to python "examples/cards.ipynb" --output "/tmp/cards_base.py"

          # Create the runnable script with proper imports
          cat > /tmp/cards.py << 'PYEOF'
          import sys
          import os

          # Add the repository root to Python path so frontend can be imported
          sys.path.insert(0, '${{ env.WORKDIR }}')
          sys.path.insert(0, '${{ env.WORKDIR }}/frontend')

          # Set environment variables if needed
          os.environ['PYTHONPATH'] = '${{ env.WORKDIR }}:${{ env.WORKDIR }}/frontend:' + os.environ.get('PYTHONPATH', '')
          PYEOF

          # Append the converted notebook content
          cat "/tmp/cards_base.py" >> /tmp/cards.py

          # Run the example
          echo "cards" > frontend/.CI
          python3 /tmp/cards.py 2>&1 | tee /tmp/ci/cards.log
          ENDSSH

      - name: Run codim
        run: |
          echo "Running codim..."
          ssh -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null \
            -i "${{ steps.keypair.outputs.KEY_PATH }}" ${{ env.USER }}@${{ env.PUBLIC_IP }} << 'ENDSSH'
          set -e
          cd ${{ env.WORKDIR }}

          # Activate Python environment
          source ~/.local/share/ppf-cts/venv/bin/activate

          # Convert notebook to Python script
          jupyter nbconvert --to python "examples/codim.ipynb" --output "/tmp/codim_base.py"

          # Create the runnable script with proper imports
          cat > /tmp/codim.py << 'PYEOF'
          import sys
          import os

          # Add the repository root to Python path so frontend can be imported
          sys.path.insert(0, '${{ env.WORKDIR }}')
          sys.path.insert(0, '${{ env.WORKDIR }}/frontend')

          # Set environment variables if needed
          os.environ['PYTHONPATH'] = '${{ env.WORKDIR }}:${{ env.WORKDIR }}/frontend:' + os.environ.get('PYTHONPATH', '')
          PYEOF

          # Append the converted notebook content
          cat "/tmp/codim_base.py" >> /tmp/codim.py

          # Run the example
          echo "codim" > frontend/.CI
          python3 /tmp/codim.py 2>&1 | tee /tmp/ci/codim.log
          ENDSSH

      - name: Run curtain
        run: |
          echo "Running curtain..."
          ssh -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null \
            -i "${{ steps.keypair.outputs.KEY_PATH }}" ${{ env.USER }}@${{ env.PUBLIC_IP }} << 'ENDSSH'
          set -e
          cd ${{ env.WORKDIR }}

          # Activate Python environment
          source ~/.local/share/ppf-cts/venv/bin/activate

          # Convert notebook to Python script
          jupyter nbconvert --to python "examples/curtain.ipynb" --output "/tmp/curtain_base.py"

          # Create the runnable script with proper imports
          cat > /tmp/curtain.py << 'PYEOF'
          import sys
          import os

          # Add the repository root to Python path so frontend can be imported
          sys.path.insert(0, '${{ env.WORKDIR }}')
          sys.path.insert(0, '${{ env.WORKDIR }}/frontend')

          # Set environment variables if needed
          os.environ['PYTHONPATH'] = '${{ env.WORKDIR }}:${{ env.WORKDIR }}/frontend:' + os.environ.get('PYTHONPATH', '')
          PYEOF

          # Append the converted notebook content
          cat "/tmp/curtain_base.py" >> /tmp/curtain.py

          # Run the example
          echo "curtain" > frontend/.CI
          python3 /tmp/curtain.py 2>&1 | tee /tmp/ci/curtain.log
          ENDSSH



      - name: Collect results
        if: success() || failure()
        run: |
          echo "Collecting results from all runs..."
          mkdir -p ci
          rsync -avz --exclude='*.bin' --exclude='*.pickle' -e "ssh -i ${{ steps.keypair.outputs.KEY_PATH }} -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null" \
            ${{ env.USER }}@${{ env.PUBLIC_IP }}:/tmp/ci/ ./ci/
          echo "## Collected Files:"
          ls -la ci/
          echo "## Run Summary:"
          for log in ci/*.log; do
            if [ -f "$log" ]; then
              echo "Found: $log"
            fi
          done

      - name: Upload artifact
        if: success() || failure()
        uses: actions/upload-artifact@v4
        with:
          name: ci-batch-1
          path: ci
          retention-days: 3

      - name: GPU information
        if: success() || failure()
        run: |
          echo "Getting GPU information..."
          ssh -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null \
            -i "${{ steps.keypair.outputs.KEY_PATH }}" ${{ env.USER }}@${{ env.PUBLIC_IP }} \
            "nvidia-smi" || echo "Failed to get GPU info"

      - name: Re-authenticate for cleanup
        if: always()
        continue-on-error: true
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_ROLE_ARN }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Cleanup - Terminate Instance
        if: always()
        continue-on-error: true
        run: |
          if [ -n "${{ steps.instance.outputs.INSTANCE_ID }}" ]; then
            echo "Initiating instance termination: ${{ steps.instance.outputs.INSTANCE_ID }}"
            aws ec2 terminate-instances \
              --instance-ids "${{ steps.instance.outputs.INSTANCE_ID }}" \
              --region "$AWS_REGION" || true
            echo "Termination initiated. Instance will terminate in the background."
            echo "Note: Full termination can take up to 30 minutes."
          fi

      - name: Cleanup - Remove Local SSH Key
        if: always()
        continue-on-error: true
        run: |
          if [ -n "${{ steps.keypair.outputs.KEY_PATH }}" ] && [ -f "${{ steps.keypair.outputs.KEY_PATH }}" ]; then
            rm -f "${{ steps.keypair.outputs.KEY_PATH }}"
            echo "Local SSH key file removed"
          fi

      - name: Summary
        if: always()
        run: |
          echo "## Workflow Summary - Batch 1"
          echo "- Region: $AWS_REGION"
          echo "- Instance Type: $INSTANCE_TYPE"
          echo "- Branch: $BRANCH"
          echo "- Examples: $EXAMPLES"
          echo "- Instance ID: ${{ steps.instance.outputs.INSTANCE_ID || 'Not launched' }}"
          echo "- Run Status: ${{ steps.run-examples.outcome || 'Not run' }}"

  run-batch-2:
    name: Run Batch 2
    runs-on: ubuntu-latest
    permissions:
      id-token: write
      contents: read

    env:
      AWS_REGION: ${{ github.event.inputs.region }}
      INSTANCE_TYPE: ${{ github.event.inputs.instance_type }}
      BRANCH: ${{ github.ref_name }}
      EXAMPLES: "domino drape fishingknot fitting"
      WORKDIR: /home/ubuntu
      USER: ubuntu

    steps:
      - name: Show input parameters
        run: |
          echo "## Input Parameters - Batch 2"
          echo "Branch: ${{ github.ref_name }}"
          echo "Instance Type: ${{ github.event.inputs.instance_type }}"
          echo "Region: ${{ github.event.inputs.region }}"
          echo "Examples: domino drape fishingknot fitting"

      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Configure AWS credentials via OIDC
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_ROLE_ARN }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Verify AWS authentication
        run: |
          echo "Testing AWS authentication..."
          aws sts get-caller-identity
          echo "AWS Region: $AWS_REGION"
          echo "Instance Type: $INSTANCE_TYPE"
          echo "Branch: $BRANCH"
          echo "Examples: $EXAMPLES"

      - name: Find Deep Learning AMI
        id: ami
        run: |
          echo "Finding latest Deep Learning AMI with GPU support..."
          AMI_ID=$(aws ec2 describe-images \
            --owners amazon \
            --filters \
              "Name=name,Values=Deep Learning Base OSS Nvidia Driver GPU AMI (Ubuntu 24.04)*" \
              "Name=state,Values=available" \
              "Name=architecture,Values=x86_64" \
            --query 'sort_by(Images, &CreationDate)[-1].ImageId' \
            --region "$AWS_REGION" \
            --output text)

          if [ "$AMI_ID" = "None" ] || [ -z "$AMI_ID" ]; then
            echo "ERROR: Deep Learning AMI not found in region $AWS_REGION"
            echo "This workflow requires the Deep Learning AMI with pre-installed NVIDIA drivers"
            echo "Please check if the AMI is available in your selected region"
            exit 1
          fi

          echo "AMI_ID=$AMI_ID" >> $GITHUB_OUTPUT
          echo "Found AMI: $AMI_ID"

      - name: Generate unique identifiers
        id: ids
        run: |
          TIMESTAMP=$(date +%Y%m%d%H%M%S)
          echo "TIMESTAMP=$TIMESTAMP" >> $GITHUB_OUTPUT

      - name: Retrieve SSH key from Parameter Store
        id: keypair
        run: |
          echo "Retrieving SSH private key from AWS Systems Manager..."
          KEY_NAME="${{ secrets.AWS_KEY_PAIR_NAME }}"

          # Retrieve the SSH private key from Parameter Store
          aws ssm get-parameter \
            --name "/github-actions/ec2/ssh-key" \
            --with-decryption \
            --query 'Parameter.Value' \
            --region "$AWS_REGION" \
            --output text > /tmp/github-actions-ec2.pem

          chmod 600 /tmp/github-actions-ec2.pem
          echo "SSH key retrieved successfully"
          echo "KEY_PATH=/tmp/github-actions-ec2.pem" >> $GITHUB_OUTPUT

      - name: Create user data script
        run: |
          cat > /tmp/user-data.sh << EOF
          #!/bin/bash
          set -e

          exec > >(tee -a /var/log/user-data.log)
          exec 2>&1

          echo "Starting user data script at \$(date)"

          # Install Rust (needed for cargo build)
          curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh -s -- -y
          source "\$HOME/.cargo/env"

          # Verify nvidia-smi is available
          if command -v nvidia-smi &> /dev/null; then
              echo "NVIDIA drivers confirmed"
              nvidia-smi
          else
              echo "Warning: nvidia-smi not found"
          fi

          # Create workspace directory
          mkdir -p ${{ env.WORKDIR }}/workspace
          chown -R ${{ env.USER }}:${{ env.USER }} ${{ env.WORKDIR }}/workspace

          nvidia-smi | tee /tmp/nvidia-smi-output.txt
          touch /tmp/setup-complete
          echo "Setup completed at \$(date)"
          EOF

      - name: Launch EC2 instance
        id: instance
        run: |
          INSTANCE_ID=$(aws ec2 run-instances \
            --image-id "${{ steps.ami.outputs.AMI_ID }}" \
            --instance-type "$INSTANCE_TYPE" \
            --key-name "${{ secrets.AWS_KEY_PAIR_NAME }}" \
            --security-group-ids "${{ secrets.AWS_SECURITY_GROUP_ID }}" \
            --block-device-mappings "DeviceName=/dev/sda1,Ebs={VolumeSize=256,VolumeType=gp3,DeleteOnTermination=true}" \
            --user-data file:///tmp/user-data.sh \
            --tag-specifications \
              "ResourceType=instance,Tags=[\
                {Key=Name,Value=gpu-runner-batch-2-${{ steps.ids.outputs.TIMESTAMP }}},\
                {Key=ManagedBy,Value=GitHubActions},\
                {Key=Purpose,Value=GPURunner},\
                {Key=Workflow,Value=${{ github.workflow }}},\
                {Key=RunId,Value=${{ github.run_id }}},\
                {Key=Branch,Value=${{ env.BRANCH }}},\
                {Key=Batch,Value=2}\
              ]" \
              "ResourceType=volume,Tags=[\
                {Key=Name,Value=gpu-runner-batch-2-${{ steps.ids.outputs.TIMESTAMP }}-volume},\
                {Key=ManagedBy,Value=GitHubActions},\
                {Key=Purpose,Value=GPURunner},\
                {Key=Workflow,Value=${{ github.workflow }}},\
                {Key=Batch,Value=2}\
              ]" \
            --instance-initiated-shutdown-behavior terminate \
            --query 'Instances[0].InstanceId' \
            --region "$AWS_REGION" \
            --output text)

          echo "INSTANCE_ID=$INSTANCE_ID" >> $GITHUB_OUTPUT
          echo "Instance launched: $INSTANCE_ID"

      - name: Wait for instance to be running
        run: |
          echo "Waiting for instance to be running..."
          aws ec2 wait instance-running \
            --instance-ids "${{ steps.instance.outputs.INSTANCE_ID }}" \
            --region "$AWS_REGION"

          PUBLIC_IP=$(aws ec2 describe-instances \
            --instance-ids "${{ steps.instance.outputs.INSTANCE_ID }}" \
            --query 'Reservations[0].Instances[0].PublicIpAddress' \
            --region "$AWS_REGION" \
            --output text)

          echo "Instance is running at: $PUBLIC_IP"
          echo "PUBLIC_IP=$PUBLIC_IP" >> $GITHUB_ENV

      - name: Wait for SSH availability
        run: |
          echo "Waiting for SSH to be available..."
          MAX_ATTEMPTS=30
          ATTEMPT=0

          while [ $ATTEMPT -lt $MAX_ATTEMPTS ]; do
            if ssh -o ConnectTimeout=5 -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null \
              -i "${{ steps.keypair.outputs.KEY_PATH }}" ${{ env.USER }}@${{ env.PUBLIC_IP }} "echo 'SSH ready'" 2>/dev/null; then
              echo "SSH connection established"
              break
            else
              ATTEMPT=$((ATTEMPT + 1))
              if [ $ATTEMPT -eq $MAX_ATTEMPTS ]; then
                echo "Failed to establish SSH connection"
                exit 1
              fi
              sleep 10
            fi
          done

      - name: Wait for instance setup
        run: |
          echo "Waiting for instance setup to complete..."
          MAX_WAIT=300
          ELAPSED=0

          while [ $ELAPSED -lt $MAX_WAIT ]; do
            if ssh -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null \
              -i "${{ steps.keypair.outputs.KEY_PATH }}" ${{ env.USER }}@${{ env.PUBLIC_IP }} \
              "test -f /tmp/setup-complete" 2>/dev/null; then
              echo "Instance setup completed"
              break
            else
              sleep 10
              ELAPSED=$((ELAPSED + 10))
              if [ $ELAPSED -ge $MAX_WAIT ]; then
                echo "Setup timeout, continuing anyway..."
                break
              fi
            fi
          done

      - name: Create archive of repository
        run: |
          echo "Creating repository archive..."
          git archive --format=tar.gz --output=/tmp/repo.tar.gz HEAD

      - name: Transfer repository to instance
        run: |
          echo "Transferring repository to instance..."
          scp -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null \
            -i "${{ steps.keypair.outputs.KEY_PATH }}" \
            /tmp/repo.tar.gz ${{ env.USER }}@${{ env.PUBLIC_IP }}:${{ env.WORKDIR }}/

          echo "Extracting repository on instance..."
          ssh -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null \
            -i "${{ steps.keypair.outputs.KEY_PATH }}" ${{ env.USER }}@${{ env.PUBLIC_IP }} \
            "cd ${{ env.WORKDIR }} && tar -xzf repo.tar.gz && rm repo.tar.gz"

      - name: Setup Python environment and run warmup
        run: |
          echo "Setting up Python environment and running warmup.py..."
          ssh -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null \
            -i "${{ steps.keypair.outputs.KEY_PATH }}" ${{ env.USER }}@${{ env.PUBLIC_IP }} << 'ENDSSH'
          set -e
          cd ${{ env.WORKDIR }}

          # Run warmup.py
          echo "Running warmup.py..."
          python3 warmup.py

          echo "Warmup completed"
          ENDSSH

      - name: Build Rust project
        run: |
          echo "Building Rust project with cargo..."
          ssh -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null \
            -i "${{ steps.keypair.outputs.KEY_PATH }}" ${{ env.USER }}@${{ env.PUBLIC_IP }} << 'ENDSSH'
          set -e
          cd ${{ env.WORKDIR }}

          # Setup Rust environment
          source "$HOME/.cargo/env"

          # Build the project
          echo "Running cargo build --release..."
          cargo build --release

          echo "Cargo build completed"
          ENDSSH

      - name: Setup CI directory
        run: |
          echo "Setting up CI directory..."
          ssh -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null \
            -i "${{ steps.keypair.outputs.KEY_PATH }}" ${{ env.USER }}@${{ env.PUBLIC_IP }} \
            "mkdir -p /tmp/ci"

      - name: Run domino
        run: |
          echo "Running domino..."
          ssh -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null \
            -i "${{ steps.keypair.outputs.KEY_PATH }}" ${{ env.USER }}@${{ env.PUBLIC_IP }} << 'ENDSSH'
          set -e
          cd ${{ env.WORKDIR }}

          # Activate Python environment
          source ~/.local/share/ppf-cts/venv/bin/activate

          # Convert notebook to Python script
          jupyter nbconvert --to python "examples/domino.ipynb" --output "/tmp/domino_base.py"

          # Create the runnable script with proper imports
          cat > /tmp/domino.py << 'PYEOF'
          import sys
          import os

          # Add the repository root to Python path so frontend can be imported
          sys.path.insert(0, '${{ env.WORKDIR }}')
          sys.path.insert(0, '${{ env.WORKDIR }}/frontend')

          # Set environment variables if needed
          os.environ['PYTHONPATH'] = '${{ env.WORKDIR }}:${{ env.WORKDIR }}/frontend:' + os.environ.get('PYTHONPATH', '')
          PYEOF

          # Append the converted notebook content
          cat "/tmp/domino_base.py" >> /tmp/domino.py

          # Run the example
          echo "domino" > frontend/.CI
          python3 /tmp/domino.py 2>&1 | tee /tmp/ci/domino.log
          ENDSSH

      - name: Run drape
        run: |
          echo "Running drape..."
          ssh -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null \
            -i "${{ steps.keypair.outputs.KEY_PATH }}" ${{ env.USER }}@${{ env.PUBLIC_IP }} << 'ENDSSH'
          set -e
          cd ${{ env.WORKDIR }}

          # Activate Python environment
          source ~/.local/share/ppf-cts/venv/bin/activate

          # Convert notebook to Python script
          jupyter nbconvert --to python "examples/drape.ipynb" --output "/tmp/drape_base.py"

          # Create the runnable script with proper imports
          cat > /tmp/drape.py << 'PYEOF'
          import sys
          import os

          # Add the repository root to Python path so frontend can be imported
          sys.path.insert(0, '${{ env.WORKDIR }}')
          sys.path.insert(0, '${{ env.WORKDIR }}/frontend')

          # Set environment variables if needed
          os.environ['PYTHONPATH'] = '${{ env.WORKDIR }}:${{ env.WORKDIR }}/frontend:' + os.environ.get('PYTHONPATH', '')
          PYEOF

          # Append the converted notebook content
          cat "/tmp/drape_base.py" >> /tmp/drape.py

          # Run the example
          echo "drape" > frontend/.CI
          python3 /tmp/drape.py 2>&1 | tee /tmp/ci/drape.log
          ENDSSH

      - name: Run fishingknot
        run: |
          echo "Running fishingknot..."
          ssh -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null \
            -i "${{ steps.keypair.outputs.KEY_PATH }}" ${{ env.USER }}@${{ env.PUBLIC_IP }} << 'ENDSSH'
          set -e
          cd ${{ env.WORKDIR }}

          # Activate Python environment
          source ~/.local/share/ppf-cts/venv/bin/activate

          # Convert notebook to Python script
          jupyter nbconvert --to python "examples/fishingknot.ipynb" --output "/tmp/fishingknot_base.py"

          # Create the runnable script with proper imports
          cat > /tmp/fishingknot.py << 'PYEOF'
          import sys
          import os

          # Add the repository root to Python path so frontend can be imported
          sys.path.insert(0, '${{ env.WORKDIR }}')
          sys.path.insert(0, '${{ env.WORKDIR }}/frontend')

          # Set environment variables if needed
          os.environ['PYTHONPATH'] = '${{ env.WORKDIR }}:${{ env.WORKDIR }}/frontend:' + os.environ.get('PYTHONPATH', '')
          PYEOF

          # Append the converted notebook content
          cat "/tmp/fishingknot_base.py" >> /tmp/fishingknot.py

          # Run the example
          echo "fishingknot" > frontend/.CI
          python3 /tmp/fishingknot.py 2>&1 | tee /tmp/ci/fishingknot.log
          ENDSSH

      - name: Run fitting
        run: |
          echo "Running fitting..."
          ssh -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null \
            -i "${{ steps.keypair.outputs.KEY_PATH }}" ${{ env.USER }}@${{ env.PUBLIC_IP }} << 'ENDSSH'
          set -e
          cd ${{ env.WORKDIR }}

          # Activate Python environment
          source ~/.local/share/ppf-cts/venv/bin/activate

          # Convert notebook to Python script
          jupyter nbconvert --to python "examples/fitting.ipynb" --output "/tmp/fitting_base.py"

          # Create the runnable script with proper imports
          cat > /tmp/fitting.py << 'PYEOF'
          import sys
          import os

          # Add the repository root to Python path so frontend can be imported
          sys.path.insert(0, '${{ env.WORKDIR }}')
          sys.path.insert(0, '${{ env.WORKDIR }}/frontend')

          # Set environment variables if needed
          os.environ['PYTHONPATH'] = '${{ env.WORKDIR }}:${{ env.WORKDIR }}/frontend:' + os.environ.get('PYTHONPATH', '')
          PYEOF

          # Append the converted notebook content
          cat "/tmp/fitting_base.py" >> /tmp/fitting.py

          # Run the example
          echo "fitting" > frontend/.CI
          python3 /tmp/fitting.py 2>&1 | tee /tmp/ci/fitting.log
          ENDSSH



      - name: Collect results
        if: success() || failure()
        run: |
          echo "Collecting results from all runs..."
          mkdir -p ci
          rsync -avz --exclude='*.bin' --exclude='*.pickle' -e "ssh -i ${{ steps.keypair.outputs.KEY_PATH }} -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null" \
            ${{ env.USER }}@${{ env.PUBLIC_IP }}:/tmp/ci/ ./ci/
          echo "## Collected Files:"
          ls -la ci/
          echo "## Run Summary:"
          for log in ci/*.log; do
            if [ -f "$log" ]; then
              echo "Found: $log"
            fi
          done

      - name: Upload artifact
        if: success() || failure()
        uses: actions/upload-artifact@v4
        with:
          name: ci-batch-2
          path: ci
          retention-days: 3

      - name: GPU information
        if: success() || failure()
        run: |
          echo "Getting GPU information..."
          ssh -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null \
            -i "${{ steps.keypair.outputs.KEY_PATH }}" ${{ env.USER }}@${{ env.PUBLIC_IP }} \
            "nvidia-smi" || echo "Failed to get GPU info"

      - name: Re-authenticate for cleanup
        if: always()
        continue-on-error: true
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_ROLE_ARN }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Cleanup - Terminate Instance
        if: always()
        continue-on-error: true
        run: |
          if [ -n "${{ steps.instance.outputs.INSTANCE_ID }}" ]; then
            echo "Initiating instance termination: ${{ steps.instance.outputs.INSTANCE_ID }}"
            aws ec2 terminate-instances \
              --instance-ids "${{ steps.instance.outputs.INSTANCE_ID }}" \
              --region "$AWS_REGION" || true
            echo "Termination initiated. Instance will terminate in the background."
            echo "Note: Full termination can take up to 30 minutes."
          fi

      - name: Cleanup - Remove Local SSH Key
        if: always()
        continue-on-error: true
        run: |
          if [ -n "${{ steps.keypair.outputs.KEY_PATH }}" ] && [ -f "${{ steps.keypair.outputs.KEY_PATH }}" ]; then
            rm -f "${{ steps.keypair.outputs.KEY_PATH }}"
            echo "Local SSH key file removed"
          fi

      - name: Summary
        if: always()
        run: |
          echo "## Workflow Summary - Batch 2"
          echo "- Region: $AWS_REGION"
          echo "- Instance Type: $INSTANCE_TYPE"
          echo "- Branch: $BRANCH"
          echo "- Examples: $EXAMPLES"
          echo "- Instance ID: ${{ steps.instance.outputs.INSTANCE_ID || 'Not launched' }}"
          echo "- Run Status: ${{ steps.run-examples.outcome || 'Not run' }}"

  run-batch-3:
    name: Run Batch 3
    runs-on: ubuntu-latest
    permissions:
      id-token: write
      contents: read

    env:
      AWS_REGION: ${{ github.event.inputs.region }}
      INSTANCE_TYPE: ${{ github.event.inputs.instance_type }}
      BRANCH: ${{ github.ref_name }}
      EXAMPLES: "friction hang needle noodle"
      WORKDIR: /home/ubuntu
      USER: ubuntu

    steps:
      - name: Show input parameters
        run: |
          echo "## Input Parameters - Batch 3"
          echo "Branch: ${{ github.ref_name }}"
          echo "Instance Type: ${{ github.event.inputs.instance_type }}"
          echo "Region: ${{ github.event.inputs.region }}"
          echo "Examples: friction hang needle noodle"

      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Configure AWS credentials via OIDC
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_ROLE_ARN }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Verify AWS authentication
        run: |
          echo "Testing AWS authentication..."
          aws sts get-caller-identity
          echo "AWS Region: $AWS_REGION"
          echo "Instance Type: $INSTANCE_TYPE"
          echo "Branch: $BRANCH"
          echo "Examples: $EXAMPLES"

      - name: Find Deep Learning AMI
        id: ami
        run: |
          echo "Finding latest Deep Learning AMI with GPU support..."
          AMI_ID=$(aws ec2 describe-images \
            --owners amazon \
            --filters \
              "Name=name,Values=Deep Learning Base OSS Nvidia Driver GPU AMI (Ubuntu 24.04)*" \
              "Name=state,Values=available" \
              "Name=architecture,Values=x86_64" \
            --query 'sort_by(Images, &CreationDate)[-1].ImageId' \
            --region "$AWS_REGION" \
            --output text)

          if [ "$AMI_ID" = "None" ] || [ -z "$AMI_ID" ]; then
            echo "ERROR: Deep Learning AMI not found in region $AWS_REGION"
            echo "This workflow requires the Deep Learning AMI with pre-installed NVIDIA drivers"
            echo "Please check if the AMI is available in your selected region"
            exit 1
          fi

          echo "AMI_ID=$AMI_ID" >> $GITHUB_OUTPUT
          echo "Found AMI: $AMI_ID"

      - name: Generate unique identifiers
        id: ids
        run: |
          TIMESTAMP=$(date +%Y%m%d%H%M%S)
          echo "TIMESTAMP=$TIMESTAMP" >> $GITHUB_OUTPUT

      - name: Retrieve SSH key from Parameter Store
        id: keypair
        run: |
          echo "Retrieving SSH private key from AWS Systems Manager..."
          KEY_NAME="${{ secrets.AWS_KEY_PAIR_NAME }}"

          # Retrieve the SSH private key from Parameter Store
          aws ssm get-parameter \
            --name "/github-actions/ec2/ssh-key" \
            --with-decryption \
            --query 'Parameter.Value' \
            --region "$AWS_REGION" \
            --output text > /tmp/github-actions-ec2.pem

          chmod 600 /tmp/github-actions-ec2.pem
          echo "SSH key retrieved successfully"
          echo "KEY_PATH=/tmp/github-actions-ec2.pem" >> $GITHUB_OUTPUT

      - name: Create user data script
        run: |
          cat > /tmp/user-data.sh << EOF
          #!/bin/bash
          set -e

          exec > >(tee -a /var/log/user-data.log)
          exec 2>&1

          echo "Starting user data script at \$(date)"

          # Install Rust (needed for cargo build)
          curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh -s -- -y
          source "\$HOME/.cargo/env"

          # Verify nvidia-smi is available
          if command -v nvidia-smi &> /dev/null; then
              echo "NVIDIA drivers confirmed"
              nvidia-smi
          else
              echo "Warning: nvidia-smi not found"
          fi

          # Create workspace directory
          mkdir -p ${{ env.WORKDIR }}/workspace
          chown -R ${{ env.USER }}:${{ env.USER }} ${{ env.WORKDIR }}/workspace

          nvidia-smi | tee /tmp/nvidia-smi-output.txt
          touch /tmp/setup-complete
          echo "Setup completed at \$(date)"
          EOF

      - name: Launch EC2 instance
        id: instance
        run: |
          INSTANCE_ID=$(aws ec2 run-instances \
            --image-id "${{ steps.ami.outputs.AMI_ID }}" \
            --instance-type "$INSTANCE_TYPE" \
            --key-name "${{ secrets.AWS_KEY_PAIR_NAME }}" \
            --security-group-ids "${{ secrets.AWS_SECURITY_GROUP_ID }}" \
            --block-device-mappings "DeviceName=/dev/sda1,Ebs={VolumeSize=256,VolumeType=gp3,DeleteOnTermination=true}" \
            --user-data file:///tmp/user-data.sh \
            --tag-specifications \
              "ResourceType=instance,Tags=[\
                {Key=Name,Value=gpu-runner-batch-3-${{ steps.ids.outputs.TIMESTAMP }}},\
                {Key=ManagedBy,Value=GitHubActions},\
                {Key=Purpose,Value=GPURunner},\
                {Key=Workflow,Value=${{ github.workflow }}},\
                {Key=RunId,Value=${{ github.run_id }}},\
                {Key=Branch,Value=${{ env.BRANCH }}},\
                {Key=Batch,Value=3}\
              ]" \
              "ResourceType=volume,Tags=[\
                {Key=Name,Value=gpu-runner-batch-3-${{ steps.ids.outputs.TIMESTAMP }}-volume},\
                {Key=ManagedBy,Value=GitHubActions},\
                {Key=Purpose,Value=GPURunner},\
                {Key=Workflow,Value=${{ github.workflow }}},\
                {Key=Batch,Value=3}\
              ]" \
            --instance-initiated-shutdown-behavior terminate \
            --query 'Instances[0].InstanceId' \
            --region "$AWS_REGION" \
            --output text)

          echo "INSTANCE_ID=$INSTANCE_ID" >> $GITHUB_OUTPUT
          echo "Instance launched: $INSTANCE_ID"

      - name: Wait for instance to be running
        run: |
          echo "Waiting for instance to be running..."
          aws ec2 wait instance-running \
            --instance-ids "${{ steps.instance.outputs.INSTANCE_ID }}" \
            --region "$AWS_REGION"

          PUBLIC_IP=$(aws ec2 describe-instances \
            --instance-ids "${{ steps.instance.outputs.INSTANCE_ID }}" \
            --query 'Reservations[0].Instances[0].PublicIpAddress' \
            --region "$AWS_REGION" \
            --output text)

          echo "Instance is running at: $PUBLIC_IP"
          echo "PUBLIC_IP=$PUBLIC_IP" >> $GITHUB_ENV

      - name: Wait for SSH availability
        run: |
          echo "Waiting for SSH to be available..."
          MAX_ATTEMPTS=30
          ATTEMPT=0

          while [ $ATTEMPT -lt $MAX_ATTEMPTS ]; do
            if ssh -o ConnectTimeout=5 -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null \
              -i "${{ steps.keypair.outputs.KEY_PATH }}" ${{ env.USER }}@${{ env.PUBLIC_IP }} "echo 'SSH ready'" 2>/dev/null; then
              echo "SSH connection established"
              break
            else
              ATTEMPT=$((ATTEMPT + 1))
              if [ $ATTEMPT -eq $MAX_ATTEMPTS ]; then
                echo "Failed to establish SSH connection"
                exit 1
              fi
              sleep 10
            fi
          done

      - name: Wait for instance setup
        run: |
          echo "Waiting for instance setup to complete..."
          MAX_WAIT=300
          ELAPSED=0

          while [ $ELAPSED -lt $MAX_WAIT ]; do
            if ssh -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null \
              -i "${{ steps.keypair.outputs.KEY_PATH }}" ${{ env.USER }}@${{ env.PUBLIC_IP }} \
              "test -f /tmp/setup-complete" 2>/dev/null; then
              echo "Instance setup completed"
              break
            else
              sleep 10
              ELAPSED=$((ELAPSED + 10))
              if [ $ELAPSED -ge $MAX_WAIT ]; then
                echo "Setup timeout, continuing anyway..."
                break
              fi
            fi
          done

      - name: Create archive of repository
        run: |
          echo "Creating repository archive..."
          git archive --format=tar.gz --output=/tmp/repo.tar.gz HEAD

      - name: Transfer repository to instance
        run: |
          echo "Transferring repository to instance..."
          scp -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null \
            -i "${{ steps.keypair.outputs.KEY_PATH }}" \
            /tmp/repo.tar.gz ${{ env.USER }}@${{ env.PUBLIC_IP }}:${{ env.WORKDIR }}/

          echo "Extracting repository on instance..."
          ssh -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null \
            -i "${{ steps.keypair.outputs.KEY_PATH }}" ${{ env.USER }}@${{ env.PUBLIC_IP }} \
            "cd ${{ env.WORKDIR }} && tar -xzf repo.tar.gz && rm repo.tar.gz"

      - name: Setup Python environment and run warmup
        run: |
          echo "Setting up Python environment and running warmup.py..."
          ssh -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null \
            -i "${{ steps.keypair.outputs.KEY_PATH }}" ${{ env.USER }}@${{ env.PUBLIC_IP }} << 'ENDSSH'
          set -e
          cd ${{ env.WORKDIR }}

          # Run warmup.py
          echo "Running warmup.py..."
          python3 warmup.py

          echo "Warmup completed"
          ENDSSH

      - name: Build Rust project
        run: |
          echo "Building Rust project with cargo..."
          ssh -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null \
            -i "${{ steps.keypair.outputs.KEY_PATH }}" ${{ env.USER }}@${{ env.PUBLIC_IP }} << 'ENDSSH'
          set -e
          cd ${{ env.WORKDIR }}

          # Setup Rust environment
          source "$HOME/.cargo/env"

          # Build the project
          echo "Running cargo build --release..."
          cargo build --release

          echo "Cargo build completed"
          ENDSSH

      - name: Setup CI directory
        run: |
          echo "Setting up CI directory..."
          ssh -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null \
            -i "${{ steps.keypair.outputs.KEY_PATH }}" ${{ env.USER }}@${{ env.PUBLIC_IP }} \
            "mkdir -p /tmp/ci"

      - name: Run friction
        run: |
          echo "Running friction..."
          ssh -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null \
            -i "${{ steps.keypair.outputs.KEY_PATH }}" ${{ env.USER }}@${{ env.PUBLIC_IP }} << 'ENDSSH'
          set -e
          cd ${{ env.WORKDIR }}

          # Activate Python environment
          source ~/.local/share/ppf-cts/venv/bin/activate

          # Convert notebook to Python script
          jupyter nbconvert --to python "examples/friction.ipynb" --output "/tmp/friction_base.py"

          # Create the runnable script with proper imports
          cat > /tmp/friction.py << 'PYEOF'
          import sys
          import os

          # Add the repository root to Python path so frontend can be imported
          sys.path.insert(0, '${{ env.WORKDIR }}')
          sys.path.insert(0, '${{ env.WORKDIR }}/frontend')

          # Set environment variables if needed
          os.environ['PYTHONPATH'] = '${{ env.WORKDIR }}:${{ env.WORKDIR }}/frontend:' + os.environ.get('PYTHONPATH', '')
          PYEOF

          # Append the converted notebook content
          cat "/tmp/friction_base.py" >> /tmp/friction.py

          # Run the example
          echo "friction" > frontend/.CI
          python3 /tmp/friction.py 2>&1 | tee /tmp/ci/friction.log
          ENDSSH

      - name: Run hang
        run: |
          echo "Running hang..."
          ssh -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null \
            -i "${{ steps.keypair.outputs.KEY_PATH }}" ${{ env.USER }}@${{ env.PUBLIC_IP }} << 'ENDSSH'
          set -e
          cd ${{ env.WORKDIR }}

          # Activate Python environment
          source ~/.local/share/ppf-cts/venv/bin/activate

          # Convert notebook to Python script
          jupyter nbconvert --to python "examples/hang.ipynb" --output "/tmp/hang_base.py"

          # Create the runnable script with proper imports
          cat > /tmp/hang.py << 'PYEOF'
          import sys
          import os

          # Add the repository root to Python path so frontend can be imported
          sys.path.insert(0, '${{ env.WORKDIR }}')
          sys.path.insert(0, '${{ env.WORKDIR }}/frontend')

          # Set environment variables if needed
          os.environ['PYTHONPATH'] = '${{ env.WORKDIR }}:${{ env.WORKDIR }}/frontend:' + os.environ.get('PYTHONPATH', '')
          PYEOF

          # Append the converted notebook content
          cat "/tmp/hang_base.py" >> /tmp/hang.py

          # Run the example
          echo "hang" > frontend/.CI
          python3 /tmp/hang.py 2>&1 | tee /tmp/ci/hang.log
          ENDSSH

      - name: Run needle
        run: |
          echo "Running needle..."
          ssh -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null \
            -i "${{ steps.keypair.outputs.KEY_PATH }}" ${{ env.USER }}@${{ env.PUBLIC_IP }} << 'ENDSSH'
          set -e
          cd ${{ env.WORKDIR }}

          # Activate Python environment
          source ~/.local/share/ppf-cts/venv/bin/activate

          # Convert notebook to Python script
          jupyter nbconvert --to python "examples/needle.ipynb" --output "/tmp/needle_base.py"

          # Create the runnable script with proper imports
          cat > /tmp/needle.py << 'PYEOF'
          import sys
          import os

          # Add the repository root to Python path so frontend can be imported
          sys.path.insert(0, '${{ env.WORKDIR }}')
          sys.path.insert(0, '${{ env.WORKDIR }}/frontend')

          # Set environment variables if needed
          os.environ['PYTHONPATH'] = '${{ env.WORKDIR }}:${{ env.WORKDIR }}/frontend:' + os.environ.get('PYTHONPATH', '')
          PYEOF

          # Append the converted notebook content
          cat "/tmp/needle_base.py" >> /tmp/needle.py

          # Run the example
          echo "needle" > frontend/.CI
          python3 /tmp/needle.py 2>&1 | tee /tmp/ci/needle.log
          ENDSSH

      - name: Run noodle
        run: |
          echo "Running noodle..."
          ssh -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null \
            -i "${{ steps.keypair.outputs.KEY_PATH }}" ${{ env.USER }}@${{ env.PUBLIC_IP }} << 'ENDSSH'
          set -e
          cd ${{ env.WORKDIR }}

          # Activate Python environment
          source ~/.local/share/ppf-cts/venv/bin/activate

          # Convert notebook to Python script
          jupyter nbconvert --to python "examples/noodle.ipynb" --output "/tmp/noodle_base.py"

          # Create the runnable script with proper imports
          cat > /tmp/noodle.py << 'PYEOF'
          import sys
          import os

          # Add the repository root to Python path so frontend can be imported
          sys.path.insert(0, '${{ env.WORKDIR }}')
          sys.path.insert(0, '${{ env.WORKDIR }}/frontend')

          # Set environment variables if needed
          os.environ['PYTHONPATH'] = '${{ env.WORKDIR }}:${{ env.WORKDIR }}/frontend:' + os.environ.get('PYTHONPATH', '')
          PYEOF

          # Append the converted notebook content
          cat "/tmp/noodle_base.py" >> /tmp/noodle.py

          # Run the example
          echo "noodle" > frontend/.CI
          python3 /tmp/noodle.py 2>&1 | tee /tmp/ci/noodle.log
          ENDSSH



      - name: Collect results
        if: success() || failure()
        run: |
          echo "Collecting results from all runs..."
          mkdir -p ci
          rsync -avz --exclude='*.bin' --exclude='*.pickle' -e "ssh -i ${{ steps.keypair.outputs.KEY_PATH }} -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null" \
            ${{ env.USER }}@${{ env.PUBLIC_IP }}:/tmp/ci/ ./ci/
          echo "## Collected Files:"
          ls -la ci/
          echo "## Run Summary:"
          for log in ci/*.log; do
            if [ -f "$log" ]; then
              echo "Found: $log"
            fi
          done

      - name: Upload artifact
        if: success() || failure()
        uses: actions/upload-artifact@v4
        with:
          name: ci-batch-3
          path: ci
          retention-days: 3

      - name: GPU information
        if: success() || failure()
        run: |
          echo "Getting GPU information..."
          ssh -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null \
            -i "${{ steps.keypair.outputs.KEY_PATH }}" ${{ env.USER }}@${{ env.PUBLIC_IP }} \
            "nvidia-smi" || echo "Failed to get GPU info"

      - name: Re-authenticate for cleanup
        if: always()
        continue-on-error: true
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_ROLE_ARN }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Cleanup - Terminate Instance
        if: always()
        continue-on-error: true
        run: |
          if [ -n "${{ steps.instance.outputs.INSTANCE_ID }}" ]; then
            echo "Initiating instance termination: ${{ steps.instance.outputs.INSTANCE_ID }}"
            aws ec2 terminate-instances \
              --instance-ids "${{ steps.instance.outputs.INSTANCE_ID }}" \
              --region "$AWS_REGION" || true
            echo "Termination initiated. Instance will terminate in the background."
            echo "Note: Full termination can take up to 30 minutes."
          fi

      - name: Cleanup - Remove Local SSH Key
        if: always()
        continue-on-error: true
        run: |
          if [ -n "${{ steps.keypair.outputs.KEY_PATH }}" ] && [ -f "${{ steps.keypair.outputs.KEY_PATH }}" ]; then
            rm -f "${{ steps.keypair.outputs.KEY_PATH }}"
            echo "Local SSH key file removed"
          fi

      - name: Summary
        if: always()
        run: |
          echo "## Workflow Summary - Batch 3"
          echo "- Region: $AWS_REGION"
          echo "- Instance Type: $INSTANCE_TYPE"
          echo "- Branch: $BRANCH"
          echo "- Examples: $EXAMPLES"
          echo "- Instance ID: ${{ steps.instance.outputs.INSTANCE_ID || 'Not launched' }}"
          echo "- Run Status: ${{ steps.run-examples.outcome || 'Not run' }}"

  run-batch-4:
    name: Run Batch 4
    runs-on: ubuntu-latest
    permissions:
      id-token: write
      contents: read

    env:
      AWS_REGION: ${{ github.event.inputs.region }}
      INSTANCE_TYPE: ${{ github.event.inputs.instance_type }}
      BRANCH: ${{ github.ref_name }}
      EXAMPLES: "ribbon roller stack trampoline"
      WORKDIR: /home/ubuntu
      USER: ubuntu

    steps:
      - name: Show input parameters
        run: |
          echo "## Input Parameters - Batch 4"
          echo "Branch: ${{ github.ref_name }}"
          echo "Instance Type: ${{ github.event.inputs.instance_type }}"
          echo "Region: ${{ github.event.inputs.region }}"
          echo "Examples: ribbon roller stack trampoline"

      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Configure AWS credentials via OIDC
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_ROLE_ARN }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Verify AWS authentication
        run: |
          echo "Testing AWS authentication..."
          aws sts get-caller-identity
          echo "AWS Region: $AWS_REGION"
          echo "Instance Type: $INSTANCE_TYPE"
          echo "Branch: $BRANCH"
          echo "Examples: $EXAMPLES"

      - name: Find Deep Learning AMI
        id: ami
        run: |
          echo "Finding latest Deep Learning AMI with GPU support..."
          AMI_ID=$(aws ec2 describe-images \
            --owners amazon \
            --filters \
              "Name=name,Values=Deep Learning Base OSS Nvidia Driver GPU AMI (Ubuntu 24.04)*" \
              "Name=state,Values=available" \
              "Name=architecture,Values=x86_64" \
            --query 'sort_by(Images, &CreationDate)[-1].ImageId' \
            --region "$AWS_REGION" \
            --output text)

          if [ "$AMI_ID" = "None" ] || [ -z "$AMI_ID" ]; then
            echo "ERROR: Deep Learning AMI not found in region $AWS_REGION"
            echo "This workflow requires the Deep Learning AMI with pre-installed NVIDIA drivers"
            echo "Please check if the AMI is available in your selected region"
            exit 1
          fi

          echo "AMI_ID=$AMI_ID" >> $GITHUB_OUTPUT
          echo "Found AMI: $AMI_ID"

      - name: Generate unique identifiers
        id: ids
        run: |
          TIMESTAMP=$(date +%Y%m%d%H%M%S)
          echo "TIMESTAMP=$TIMESTAMP" >> $GITHUB_OUTPUT

      - name: Retrieve SSH key from Parameter Store
        id: keypair
        run: |
          echo "Retrieving SSH private key from AWS Systems Manager..."
          KEY_NAME="${{ secrets.AWS_KEY_PAIR_NAME }}"

          # Retrieve the SSH private key from Parameter Store
          aws ssm get-parameter \
            --name "/github-actions/ec2/ssh-key" \
            --with-decryption \
            --query 'Parameter.Value' \
            --region "$AWS_REGION" \
            --output text > /tmp/github-actions-ec2.pem

          chmod 600 /tmp/github-actions-ec2.pem
          echo "SSH key retrieved successfully"
          echo "KEY_PATH=/tmp/github-actions-ec2.pem" >> $GITHUB_OUTPUT

      - name: Create user data script
        run: |
          cat > /tmp/user-data.sh << EOF
          #!/bin/bash
          set -e

          exec > >(tee -a /var/log/user-data.log)
          exec 2>&1

          echo "Starting user data script at \$(date)"

          # Install Rust (needed for cargo build)
          curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh -s -- -y
          source "\$HOME/.cargo/env"

          # Verify nvidia-smi is available
          if command -v nvidia-smi &> /dev/null; then
              echo "NVIDIA drivers confirmed"
              nvidia-smi
          else
              echo "Warning: nvidia-smi not found"
          fi

          # Create workspace directory
          mkdir -p ${{ env.WORKDIR }}/workspace
          chown -R ${{ env.USER }}:${{ env.USER }} ${{ env.WORKDIR }}/workspace

          nvidia-smi | tee /tmp/nvidia-smi-output.txt
          touch /tmp/setup-complete
          echo "Setup completed at \$(date)"
          EOF

      - name: Launch EC2 instance
        id: instance
        run: |
          INSTANCE_ID=$(aws ec2 run-instances \
            --image-id "${{ steps.ami.outputs.AMI_ID }}" \
            --instance-type "$INSTANCE_TYPE" \
            --key-name "${{ secrets.AWS_KEY_PAIR_NAME }}" \
            --security-group-ids "${{ secrets.AWS_SECURITY_GROUP_ID }}" \
            --block-device-mappings "DeviceName=/dev/sda1,Ebs={VolumeSize=256,VolumeType=gp3,DeleteOnTermination=true}" \
            --user-data file:///tmp/user-data.sh \
            --tag-specifications \
              "ResourceType=instance,Tags=[\
                {Key=Name,Value=gpu-runner-batch-4-${{ steps.ids.outputs.TIMESTAMP }}},\
                {Key=ManagedBy,Value=GitHubActions},\
                {Key=Purpose,Value=GPURunner},\
                {Key=Workflow,Value=${{ github.workflow }}},\
                {Key=RunId,Value=${{ github.run_id }}},\
                {Key=Branch,Value=${{ env.BRANCH }}},\
                {Key=Batch,Value=4}\
              ]" \
              "ResourceType=volume,Tags=[\
                {Key=Name,Value=gpu-runner-batch-4-${{ steps.ids.outputs.TIMESTAMP }}-volume},\
                {Key=ManagedBy,Value=GitHubActions},\
                {Key=Purpose,Value=GPURunner},\
                {Key=Workflow,Value=${{ github.workflow }}},\
                {Key=Batch,Value=4}\
              ]" \
            --instance-initiated-shutdown-behavior terminate \
            --query 'Instances[0].InstanceId' \
            --region "$AWS_REGION" \
            --output text)

          echo "INSTANCE_ID=$INSTANCE_ID" >> $GITHUB_OUTPUT
          echo "Instance launched: $INSTANCE_ID"

      - name: Wait for instance to be running
        run: |
          echo "Waiting for instance to be running..."
          aws ec2 wait instance-running \
            --instance-ids "${{ steps.instance.outputs.INSTANCE_ID }}" \
            --region "$AWS_REGION"

          PUBLIC_IP=$(aws ec2 describe-instances \
            --instance-ids "${{ steps.instance.outputs.INSTANCE_ID }}" \
            --query 'Reservations[0].Instances[0].PublicIpAddress' \
            --region "$AWS_REGION" \
            --output text)

          echo "Instance is running at: $PUBLIC_IP"
          echo "PUBLIC_IP=$PUBLIC_IP" >> $GITHUB_ENV

      - name: Wait for SSH availability
        run: |
          echo "Waiting for SSH to be available..."
          MAX_ATTEMPTS=30
          ATTEMPT=0

          while [ $ATTEMPT -lt $MAX_ATTEMPTS ]; do
            if ssh -o ConnectTimeout=5 -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null \
              -i "${{ steps.keypair.outputs.KEY_PATH }}" ${{ env.USER }}@${{ env.PUBLIC_IP }} "echo 'SSH ready'" 2>/dev/null; then
              echo "SSH connection established"
              break
            else
              ATTEMPT=$((ATTEMPT + 1))
              if [ $ATTEMPT -eq $MAX_ATTEMPTS ]; then
                echo "Failed to establish SSH connection"
                exit 1
              fi
              sleep 10
            fi
          done

      - name: Wait for instance setup
        run: |
          echo "Waiting for instance setup to complete..."
          MAX_WAIT=300
          ELAPSED=0

          while [ $ELAPSED -lt $MAX_WAIT ]; do
            if ssh -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null \
              -i "${{ steps.keypair.outputs.KEY_PATH }}" ${{ env.USER }}@${{ env.PUBLIC_IP }} \
              "test -f /tmp/setup-complete" 2>/dev/null; then
              echo "Instance setup completed"
              break
            else
              sleep 10
              ELAPSED=$((ELAPSED + 10))
              if [ $ELAPSED -ge $MAX_WAIT ]; then
                echo "Setup timeout, continuing anyway..."
                break
              fi
            fi
          done

      - name: Create archive of repository
        run: |
          echo "Creating repository archive..."
          git archive --format=tar.gz --output=/tmp/repo.tar.gz HEAD

      - name: Transfer repository to instance
        run: |
          echo "Transferring repository to instance..."
          scp -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null \
            -i "${{ steps.keypair.outputs.KEY_PATH }}" \
            /tmp/repo.tar.gz ${{ env.USER }}@${{ env.PUBLIC_IP }}:${{ env.WORKDIR }}/

          echo "Extracting repository on instance..."
          ssh -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null \
            -i "${{ steps.keypair.outputs.KEY_PATH }}" ${{ env.USER }}@${{ env.PUBLIC_IP }} \
            "cd ${{ env.WORKDIR }} && tar -xzf repo.tar.gz && rm repo.tar.gz"

      - name: Setup Python environment and run warmup
        run: |
          echo "Setting up Python environment and running warmup.py..."
          ssh -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null \
            -i "${{ steps.keypair.outputs.KEY_PATH }}" ${{ env.USER }}@${{ env.PUBLIC_IP }} << 'ENDSSH'
          set -e
          cd ${{ env.WORKDIR }}

          # Run warmup.py
          echo "Running warmup.py..."
          python3 warmup.py

          echo "Warmup completed"
          ENDSSH

      - name: Build Rust project
        run: |
          echo "Building Rust project with cargo..."
          ssh -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null \
            -i "${{ steps.keypair.outputs.KEY_PATH }}" ${{ env.USER }}@${{ env.PUBLIC_IP }} << 'ENDSSH'
          set -e
          cd ${{ env.WORKDIR }}

          # Setup Rust environment
          source "$HOME/.cargo/env"

          # Build the project
          echo "Running cargo build --release..."
          cargo build --release

          echo "Cargo build completed"
          ENDSSH

      - name: Setup CI directory
        run: |
          echo "Setting up CI directory..."
          ssh -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null \
            -i "${{ steps.keypair.outputs.KEY_PATH }}" ${{ env.USER }}@${{ env.PUBLIC_IP }} \
            "mkdir -p /tmp/ci"

      - name: Run ribbon
        run: |
          echo "Running ribbon..."
          ssh -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null \
            -i "${{ steps.keypair.outputs.KEY_PATH }}" ${{ env.USER }}@${{ env.PUBLIC_IP }} << 'ENDSSH'
          set -e
          cd ${{ env.WORKDIR }}

          # Activate Python environment
          source ~/.local/share/ppf-cts/venv/bin/activate

          # Convert notebook to Python script
          jupyter nbconvert --to python "examples/ribbon.ipynb" --output "/tmp/ribbon_base.py"

          # Create the runnable script with proper imports
          cat > /tmp/ribbon.py << 'PYEOF'
          import sys
          import os

          # Add the repository root to Python path so frontend can be imported
          sys.path.insert(0, '${{ env.WORKDIR }}')
          sys.path.insert(0, '${{ env.WORKDIR }}/frontend')

          # Set environment variables if needed
          os.environ['PYTHONPATH'] = '${{ env.WORKDIR }}:${{ env.WORKDIR }}/frontend:' + os.environ.get('PYTHONPATH', '')
          PYEOF

          # Append the converted notebook content
          cat "/tmp/ribbon_base.py" >> /tmp/ribbon.py

          # Run the example
          echo "ribbon" > frontend/.CI
          python3 /tmp/ribbon.py 2>&1 | tee /tmp/ci/ribbon.log
          ENDSSH

      - name: Run roller
        run: |
          echo "Running roller..."
          ssh -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null \
            -i "${{ steps.keypair.outputs.KEY_PATH }}" ${{ env.USER }}@${{ env.PUBLIC_IP }} << 'ENDSSH'
          set -e
          cd ${{ env.WORKDIR }}

          # Activate Python environment
          source ~/.local/share/ppf-cts/venv/bin/activate

          # Convert notebook to Python script
          jupyter nbconvert --to python "examples/roller.ipynb" --output "/tmp/roller_base.py"

          # Create the runnable script with proper imports
          cat > /tmp/roller.py << 'PYEOF'
          import sys
          import os

          # Add the repository root to Python path so frontend can be imported
          sys.path.insert(0, '${{ env.WORKDIR }}')
          sys.path.insert(0, '${{ env.WORKDIR }}/frontend')

          # Set environment variables if needed
          os.environ['PYTHONPATH'] = '${{ env.WORKDIR }}:${{ env.WORKDIR }}/frontend:' + os.environ.get('PYTHONPATH', '')
          PYEOF

          # Append the converted notebook content
          cat "/tmp/roller_base.py" >> /tmp/roller.py

          # Run the example
          echo "roller" > frontend/.CI
          python3 /tmp/roller.py 2>&1 | tee /tmp/ci/roller.log
          ENDSSH

      - name: Run stack
        run: |
          echo "Running stack..."
          ssh -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null \
            -i "${{ steps.keypair.outputs.KEY_PATH }}" ${{ env.USER }}@${{ env.PUBLIC_IP }} << 'ENDSSH'
          set -e
          cd ${{ env.WORKDIR }}

          # Activate Python environment
          source ~/.local/share/ppf-cts/venv/bin/activate

          # Convert notebook to Python script
          jupyter nbconvert --to python "examples/stack.ipynb" --output "/tmp/stack_base.py"

          # Create the runnable script with proper imports
          cat > /tmp/stack.py << 'PYEOF'
          import sys
          import os

          # Add the repository root to Python path so frontend can be imported
          sys.path.insert(0, '${{ env.WORKDIR }}')
          sys.path.insert(0, '${{ env.WORKDIR }}/frontend')

          # Set environment variables if needed
          os.environ['PYTHONPATH'] = '${{ env.WORKDIR }}:${{ env.WORKDIR }}/frontend:' + os.environ.get('PYTHONPATH', '')
          PYEOF

          # Append the converted notebook content
          cat "/tmp/stack_base.py" >> /tmp/stack.py

          # Run the example
          echo "stack" > frontend/.CI
          python3 /tmp/stack.py 2>&1 | tee /tmp/ci/stack.log
          ENDSSH

      - name: Run trampoline
        run: |
          echo "Running trampoline..."
          ssh -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null \
            -i "${{ steps.keypair.outputs.KEY_PATH }}" ${{ env.USER }}@${{ env.PUBLIC_IP }} << 'ENDSSH'
          set -e
          cd ${{ env.WORKDIR }}

          # Activate Python environment
          source ~/.local/share/ppf-cts/venv/bin/activate

          # Convert notebook to Python script
          jupyter nbconvert --to python "examples/trampoline.ipynb" --output "/tmp/trampoline_base.py"

          # Create the runnable script with proper imports
          cat > /tmp/trampoline.py << 'PYEOF'
          import sys
          import os

          # Add the repository root to Python path so frontend can be imported
          sys.path.insert(0, '${{ env.WORKDIR }}')
          sys.path.insert(0, '${{ env.WORKDIR }}/frontend')

          # Set environment variables if needed
          os.environ['PYTHONPATH'] = '${{ env.WORKDIR }}:${{ env.WORKDIR }}/frontend:' + os.environ.get('PYTHONPATH', '')
          PYEOF

          # Append the converted notebook content
          cat "/tmp/trampoline_base.py" >> /tmp/trampoline.py

          # Run the example
          echo "trampoline" > frontend/.CI
          python3 /tmp/trampoline.py 2>&1 | tee /tmp/ci/trampoline.log
          ENDSSH



      - name: Collect results
        if: success() || failure()
        run: |
          echo "Collecting results from all runs..."
          mkdir -p ci
          rsync -avz --exclude='*.bin' --exclude='*.pickle' -e "ssh -i ${{ steps.keypair.outputs.KEY_PATH }} -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null" \
            ${{ env.USER }}@${{ env.PUBLIC_IP }}:/tmp/ci/ ./ci/
          echo "## Collected Files:"
          ls -la ci/
          echo "## Run Summary:"
          for log in ci/*.log; do
            if [ -f "$log" ]; then
              echo "Found: $log"
            fi
          done

      - name: Upload artifact
        if: success() || failure()
        uses: actions/upload-artifact@v4
        with:
          name: ci-batch-4
          path: ci
          retention-days: 3

      - name: GPU information
        if: success() || failure()
        run: |
          echo "Getting GPU information..."
          ssh -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null \
            -i "${{ steps.keypair.outputs.KEY_PATH }}" ${{ env.USER }}@${{ env.PUBLIC_IP }} \
            "nvidia-smi" || echo "Failed to get GPU info"

      - name: Re-authenticate for cleanup
        if: always()
        continue-on-error: true
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_ROLE_ARN }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Cleanup - Terminate Instance
        if: always()
        continue-on-error: true
        run: |
          if [ -n "${{ steps.instance.outputs.INSTANCE_ID }}" ]; then
            echo "Initiating instance termination: ${{ steps.instance.outputs.INSTANCE_ID }}"
            aws ec2 terminate-instances \
              --instance-ids "${{ steps.instance.outputs.INSTANCE_ID }}" \
              --region "$AWS_REGION" || true
            echo "Termination initiated. Instance will terminate in the background."
            echo "Note: Full termination can take up to 30 minutes."
          fi

      - name: Cleanup - Remove Local SSH Key
        if: always()
        continue-on-error: true
        run: |
          if [ -n "${{ steps.keypair.outputs.KEY_PATH }}" ] && [ -f "${{ steps.keypair.outputs.KEY_PATH }}" ]; then
            rm -f "${{ steps.keypair.outputs.KEY_PATH }}"
            echo "Local SSH key file removed"
          fi

      - name: Summary
        if: always()
        run: |
          echo "## Workflow Summary - Batch 4"
          echo "- Region: $AWS_REGION"
          echo "- Instance Type: $INSTANCE_TYPE"
          echo "- Branch: $BRANCH"
          echo "- Examples: $EXAMPLES"
          echo "- Instance ID: ${{ steps.instance.outputs.INSTANCE_ID || 'Not launched' }}"
          echo "- Run Status: ${{ steps.run-examples.outcome || 'Not run' }}"

  run-batch-5:
    name: Run Batch 5
    runs-on: ubuntu-latest
    permissions:
      id-token: write
      contents: read

    env:
      AWS_REGION: ${{ github.event.inputs.region }}
      INSTANCE_TYPE: ${{ github.event.inputs.instance_type }}
      BRANCH: ${{ github.ref_name }}
      EXAMPLES: "trapped twist woven yarn"
      WORKDIR: /home/ubuntu
      USER: ubuntu

    steps:
      - name: Show input parameters
        run: |
          echo "## Input Parameters - Batch 5"
          echo "Branch: ${{ github.ref_name }}"
          echo "Instance Type: ${{ github.event.inputs.instance_type }}"
          echo "Region: ${{ github.event.inputs.region }}"
          echo "Examples: trapped twist woven yarn"

      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Configure AWS credentials via OIDC
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_ROLE_ARN }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Verify AWS authentication
        run: |
          echo "Testing AWS authentication..."
          aws sts get-caller-identity
          echo "AWS Region: $AWS_REGION"
          echo "Instance Type: $INSTANCE_TYPE"
          echo "Branch: $BRANCH"
          echo "Examples: $EXAMPLES"

      - name: Find Deep Learning AMI
        id: ami
        run: |
          echo "Finding latest Deep Learning AMI with GPU support..."
          AMI_ID=$(aws ec2 describe-images \
            --owners amazon \
            --filters \
              "Name=name,Values=Deep Learning Base OSS Nvidia Driver GPU AMI (Ubuntu 24.04)*" \
              "Name=state,Values=available" \
              "Name=architecture,Values=x86_64" \
            --query 'sort_by(Images, &CreationDate)[-1].ImageId' \
            --region "$AWS_REGION" \
            --output text)

          if [ "$AMI_ID" = "None" ] || [ -z "$AMI_ID" ]; then
            echo "ERROR: Deep Learning AMI not found in region $AWS_REGION"
            echo "This workflow requires the Deep Learning AMI with pre-installed NVIDIA drivers"
            echo "Please check if the AMI is available in your selected region"
            exit 1
          fi

          echo "AMI_ID=$AMI_ID" >> $GITHUB_OUTPUT
          echo "Found AMI: $AMI_ID"

      - name: Generate unique identifiers
        id: ids
        run: |
          TIMESTAMP=$(date +%Y%m%d%H%M%S)
          echo "TIMESTAMP=$TIMESTAMP" >> $GITHUB_OUTPUT

      - name: Retrieve SSH key from Parameter Store
        id: keypair
        run: |
          echo "Retrieving SSH private key from AWS Systems Manager..."
          KEY_NAME="${{ secrets.AWS_KEY_PAIR_NAME }}"

          # Retrieve the SSH private key from Parameter Store
          aws ssm get-parameter \
            --name "/github-actions/ec2/ssh-key" \
            --with-decryption \
            --query 'Parameter.Value' \
            --region "$AWS_REGION" \
            --output text > /tmp/github-actions-ec2.pem

          chmod 600 /tmp/github-actions-ec2.pem
          echo "SSH key retrieved successfully"
          echo "KEY_PATH=/tmp/github-actions-ec2.pem" >> $GITHUB_OUTPUT

      - name: Create user data script
        run: |
          cat > /tmp/user-data.sh << EOF
          #!/bin/bash
          set -e

          exec > >(tee -a /var/log/user-data.log)
          exec 2>&1

          echo "Starting user data script at \$(date)"

          # Install Rust (needed for cargo build)
          curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh -s -- -y
          source "\$HOME/.cargo/env"

          # Verify nvidia-smi is available
          if command -v nvidia-smi &> /dev/null; then
              echo "NVIDIA drivers confirmed"
              nvidia-smi
          else
              echo "Warning: nvidia-smi not found"
          fi

          # Create workspace directory
          mkdir -p ${{ env.WORKDIR }}/workspace
          chown -R ${{ env.USER }}:${{ env.USER }} ${{ env.WORKDIR }}/workspace

          nvidia-smi | tee /tmp/nvidia-smi-output.txt
          touch /tmp/setup-complete
          echo "Setup completed at \$(date)"
          EOF

      - name: Launch EC2 instance
        id: instance
        run: |
          INSTANCE_ID=$(aws ec2 run-instances \
            --image-id "${{ steps.ami.outputs.AMI_ID }}" \
            --instance-type "$INSTANCE_TYPE" \
            --key-name "${{ secrets.AWS_KEY_PAIR_NAME }}" \
            --security-group-ids "${{ secrets.AWS_SECURITY_GROUP_ID }}" \
            --block-device-mappings "DeviceName=/dev/sda1,Ebs={VolumeSize=256,VolumeType=gp3,DeleteOnTermination=true}" \
            --user-data file:///tmp/user-data.sh \
            --tag-specifications \
              "ResourceType=instance,Tags=[\
                {Key=Name,Value=gpu-runner-batch-5-${{ steps.ids.outputs.TIMESTAMP }}},\
                {Key=ManagedBy,Value=GitHubActions},\
                {Key=Purpose,Value=GPURunner},\
                {Key=Workflow,Value=${{ github.workflow }}},\
                {Key=RunId,Value=${{ github.run_id }}},\
                {Key=Branch,Value=${{ env.BRANCH }}},\
                {Key=Batch,Value=5}\
              ]" \
              "ResourceType=volume,Tags=[\
                {Key=Name,Value=gpu-runner-batch-5-${{ steps.ids.outputs.TIMESTAMP }}-volume},\
                {Key=ManagedBy,Value=GitHubActions},\
                {Key=Purpose,Value=GPURunner},\
                {Key=Workflow,Value=${{ github.workflow }}},\
                {Key=Batch,Value=5}\
              ]" \
            --instance-initiated-shutdown-behavior terminate \
            --query 'Instances[0].InstanceId' \
            --region "$AWS_REGION" \
            --output text)

          echo "INSTANCE_ID=$INSTANCE_ID" >> $GITHUB_OUTPUT
          echo "Instance launched: $INSTANCE_ID"

      - name: Wait for instance to be running
        run: |
          echo "Waiting for instance to be running..."
          aws ec2 wait instance-running \
            --instance-ids "${{ steps.instance.outputs.INSTANCE_ID }}" \
            --region "$AWS_REGION"

          PUBLIC_IP=$(aws ec2 describe-instances \
            --instance-ids "${{ steps.instance.outputs.INSTANCE_ID }}" \
            --query 'Reservations[0].Instances[0].PublicIpAddress' \
            --region "$AWS_REGION" \
            --output text)

          echo "Instance is running at: $PUBLIC_IP"
          echo "PUBLIC_IP=$PUBLIC_IP" >> $GITHUB_ENV

      - name: Wait for SSH availability
        run: |
          echo "Waiting for SSH to be available..."
          MAX_ATTEMPTS=30
          ATTEMPT=0

          while [ $ATTEMPT -lt $MAX_ATTEMPTS ]; do
            if ssh -o ConnectTimeout=5 -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null \
              -i "${{ steps.keypair.outputs.KEY_PATH }}" ${{ env.USER }}@${{ env.PUBLIC_IP }} "echo 'SSH ready'" 2>/dev/null; then
              echo "SSH connection established"
              break
            else
              ATTEMPT=$((ATTEMPT + 1))
              if [ $ATTEMPT -eq $MAX_ATTEMPTS ]; then
                echo "Failed to establish SSH connection"
                exit 1
              fi
              sleep 10
            fi
          done

      - name: Wait for instance setup
        run: |
          echo "Waiting for instance setup to complete..."
          MAX_WAIT=300
          ELAPSED=0

          while [ $ELAPSED -lt $MAX_WAIT ]; do
            if ssh -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null \
              -i "${{ steps.keypair.outputs.KEY_PATH }}" ${{ env.USER }}@${{ env.PUBLIC_IP }} \
              "test -f /tmp/setup-complete" 2>/dev/null; then
              echo "Instance setup completed"
              break
            else
              sleep 10
              ELAPSED=$((ELAPSED + 10))
              if [ $ELAPSED -ge $MAX_WAIT ]; then
                echo "Setup timeout, continuing anyway..."
                break
              fi
            fi
          done

      - name: Create archive of repository
        run: |
          echo "Creating repository archive..."
          git archive --format=tar.gz --output=/tmp/repo.tar.gz HEAD

      - name: Transfer repository to instance
        run: |
          echo "Transferring repository to instance..."
          scp -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null \
            -i "${{ steps.keypair.outputs.KEY_PATH }}" \
            /tmp/repo.tar.gz ${{ env.USER }}@${{ env.PUBLIC_IP }}:${{ env.WORKDIR }}/

          echo "Extracting repository on instance..."
          ssh -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null \
            -i "${{ steps.keypair.outputs.KEY_PATH }}" ${{ env.USER }}@${{ env.PUBLIC_IP }} \
            "cd ${{ env.WORKDIR }} && tar -xzf repo.tar.gz && rm repo.tar.gz"

      - name: Setup Python environment and run warmup
        run: |
          echo "Setting up Python environment and running warmup.py..."
          ssh -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null \
            -i "${{ steps.keypair.outputs.KEY_PATH }}" ${{ env.USER }}@${{ env.PUBLIC_IP }} << 'ENDSSH'
          set -e
          cd ${{ env.WORKDIR }}

          # Run warmup.py
          echo "Running warmup.py..."
          python3 warmup.py

          echo "Warmup completed"
          ENDSSH

      - name: Build Rust project
        run: |
          echo "Building Rust project with cargo..."
          ssh -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null \
            -i "${{ steps.keypair.outputs.KEY_PATH }}" ${{ env.USER }}@${{ env.PUBLIC_IP }} << 'ENDSSH'
          set -e
          cd ${{ env.WORKDIR }}

          # Setup Rust environment
          source "$HOME/.cargo/env"

          # Build the project
          echo "Running cargo build --release..."
          cargo build --release

          echo "Cargo build completed"
          ENDSSH

      - name: Setup CI directory
        run: |
          echo "Setting up CI directory..."
          ssh -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null \
            -i "${{ steps.keypair.outputs.KEY_PATH }}" ${{ env.USER }}@${{ env.PUBLIC_IP }} \
            "mkdir -p /tmp/ci"

      - name: Run trapped
        run: |
          echo "Running trapped..."
          ssh -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null \
            -i "${{ steps.keypair.outputs.KEY_PATH }}" ${{ env.USER }}@${{ env.PUBLIC_IP }} << 'ENDSSH'
          set -e
          cd ${{ env.WORKDIR }}

          # Activate Python environment
          source ~/.local/share/ppf-cts/venv/bin/activate

          # Convert notebook to Python script
          jupyter nbconvert --to python "examples/trapped.ipynb" --output "/tmp/trapped_base.py"

          # Create the runnable script with proper imports
          cat > /tmp/trapped.py << 'PYEOF'
          import sys
          import os

          # Add the repository root to Python path so frontend can be imported
          sys.path.insert(0, '${{ env.WORKDIR }}')
          sys.path.insert(0, '${{ env.WORKDIR }}/frontend')

          # Set environment variables if needed
          os.environ['PYTHONPATH'] = '${{ env.WORKDIR }}:${{ env.WORKDIR }}/frontend:' + os.environ.get('PYTHONPATH', '')
          PYEOF

          # Append the converted notebook content
          cat "/tmp/trapped_base.py" >> /tmp/trapped.py

          # Run the example
          echo "trapped" > frontend/.CI
          python3 /tmp/trapped.py 2>&1 | tee /tmp/ci/trapped.log
          ENDSSH

      - name: Run twist
        run: |
          echo "Running twist..."
          ssh -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null \
            -i "${{ steps.keypair.outputs.KEY_PATH }}" ${{ env.USER }}@${{ env.PUBLIC_IP }} << 'ENDSSH'
          set -e
          cd ${{ env.WORKDIR }}

          # Activate Python environment
          source ~/.local/share/ppf-cts/venv/bin/activate

          # Convert notebook to Python script
          jupyter nbconvert --to python "examples/twist.ipynb" --output "/tmp/twist_base.py"

          # Create the runnable script with proper imports
          cat > /tmp/twist.py << 'PYEOF'
          import sys
          import os

          # Add the repository root to Python path so frontend can be imported
          sys.path.insert(0, '${{ env.WORKDIR }}')
          sys.path.insert(0, '${{ env.WORKDIR }}/frontend')

          # Set environment variables if needed
          os.environ['PYTHONPATH'] = '${{ env.WORKDIR }}:${{ env.WORKDIR }}/frontend:' + os.environ.get('PYTHONPATH', '')
          PYEOF

          # Append the converted notebook content
          cat "/tmp/twist_base.py" >> /tmp/twist.py

          # Run the example
          echo "twist" > frontend/.CI
          python3 /tmp/twist.py 2>&1 | tee /tmp/ci/twist.log
          ENDSSH

      - name: Run woven
        run: |
          echo "Running woven..."
          ssh -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null \
            -i "${{ steps.keypair.outputs.KEY_PATH }}" ${{ env.USER }}@${{ env.PUBLIC_IP }} << 'ENDSSH'
          set -e
          cd ${{ env.WORKDIR }}

          # Activate Python environment
          source ~/.local/share/ppf-cts/venv/bin/activate

          # Convert notebook to Python script
          jupyter nbconvert --to python "examples/woven.ipynb" --output "/tmp/woven_base.py"

          # Create the runnable script with proper imports
          cat > /tmp/woven.py << 'PYEOF'
          import sys
          import os

          # Add the repository root to Python path so frontend can be imported
          sys.path.insert(0, '${{ env.WORKDIR }}')
          sys.path.insert(0, '${{ env.WORKDIR }}/frontend')

          # Set environment variables if needed
          os.environ['PYTHONPATH'] = '${{ env.WORKDIR }}:${{ env.WORKDIR }}/frontend:' + os.environ.get('PYTHONPATH', '')
          PYEOF

          # Append the converted notebook content
          cat "/tmp/woven_base.py" >> /tmp/woven.py

          # Run the example
          echo "woven" > frontend/.CI
          python3 /tmp/woven.py 2>&1 | tee /tmp/ci/woven.log
          ENDSSH

      - name: Run yarn
        run: |
          echo "Running yarn..."
          ssh -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null \
            -i "${{ steps.keypair.outputs.KEY_PATH }}" ${{ env.USER }}@${{ env.PUBLIC_IP }} << 'ENDSSH'
          set -e
          cd ${{ env.WORKDIR }}

          # Activate Python environment
          source ~/.local/share/ppf-cts/venv/bin/activate

          # Convert notebook to Python script
          jupyter nbconvert --to python "examples/yarn.ipynb" --output "/tmp/yarn_base.py"

          # Create the runnable script with proper imports
          cat > /tmp/yarn.py << 'PYEOF'
          import sys
          import os

          # Add the repository root to Python path so frontend can be imported
          sys.path.insert(0, '${{ env.WORKDIR }}')
          sys.path.insert(0, '${{ env.WORKDIR }}/frontend')

          # Set environment variables if needed
          os.environ['PYTHONPATH'] = '${{ env.WORKDIR }}:${{ env.WORKDIR }}/frontend:' + os.environ.get('PYTHONPATH', '')
          PYEOF

          # Append the converted notebook content
          cat "/tmp/yarn_base.py" >> /tmp/yarn.py

          # Run the example
          echo "yarn" > frontend/.CI
          python3 /tmp/yarn.py 2>&1 | tee /tmp/ci/yarn.log
          ENDSSH



      - name: Collect results
        if: success() || failure()
        run: |
          echo "Collecting results from all runs..."
          mkdir -p ci
          rsync -avz --exclude='*.bin' --exclude='*.pickle' -e "ssh -i ${{ steps.keypair.outputs.KEY_PATH }} -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null" \
            ${{ env.USER }}@${{ env.PUBLIC_IP }}:/tmp/ci/ ./ci/
          echo "## Collected Files:"
          ls -la ci/
          echo "## Run Summary:"
          for log in ci/*.log; do
            if [ -f "$log" ]; then
              echo "Found: $log"
            fi
          done

      - name: Upload artifact
        if: success() || failure()
        uses: actions/upload-artifact@v4
        with:
          name: ci-batch-5
          path: ci
          retention-days: 3

      - name: GPU information
        if: success() || failure()
        run: |
          echo "Getting GPU information..."
          ssh -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null \
            -i "${{ steps.keypair.outputs.KEY_PATH }}" ${{ env.USER }}@${{ env.PUBLIC_IP }} \
            "nvidia-smi" || echo "Failed to get GPU info"

      - name: Re-authenticate for cleanup
        if: always()
        continue-on-error: true
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_ROLE_ARN }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Cleanup - Terminate Instance
        if: always()
        continue-on-error: true
        run: |
          if [ -n "${{ steps.instance.outputs.INSTANCE_ID }}" ]; then
            echo "Initiating instance termination: ${{ steps.instance.outputs.INSTANCE_ID }}"
            aws ec2 terminate-instances \
              --instance-ids "${{ steps.instance.outputs.INSTANCE_ID }}" \
              --region "$AWS_REGION" || true
            echo "Termination initiated. Instance will terminate in the background."
            echo "Note: Full termination can take up to 30 minutes."
          fi

      - name: Cleanup - Remove Local SSH Key
        if: always()
        continue-on-error: true
        run: |
          if [ -n "${{ steps.keypair.outputs.KEY_PATH }}" ] && [ -f "${{ steps.keypair.outputs.KEY_PATH }}" ]; then
            rm -f "${{ steps.keypair.outputs.KEY_PATH }}"
            echo "Local SSH key file removed"
          fi

      - name: Summary
        if: always()
        run: |
          echo "## Workflow Summary - Batch 5"
          echo "- Region: $AWS_REGION"
          echo "- Instance Type: $INSTANCE_TYPE"
          echo "- Branch: $BRANCH"
          echo "- Examples: $EXAMPLES"
          echo "- Instance ID: ${{ steps.instance.outputs.INSTANCE_ID || 'Not launched' }}"
          echo "- Run Status: ${{ steps.run-examples.outcome || 'Not run' }}"

